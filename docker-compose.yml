version: "3.8"

services:
  api:
    build: .
    env_file:
      - .env
    read_only: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    ports:
      - "8000:8000"
    # Run the unified runtime service.
    command: ["python", "-m", "unified_runtime.__main__"]
    environment:
      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_JSON=${LOG_JSON:-1}
      # Core dependencies
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-web_corpus}
      - VLLM_ENDPOINT=${VLLM_ENDPOINT:-http://vllm:8000}
      - VLLM_ENDPOINT_SMALL=${VLLM_ENDPOINT_SMALL}
      - VLLM_ENDPOINT_LARGE=${VLLM_ENDPOINT_LARGE}
      # Security and limits
      - TENANCY_MODE=${TENANCY_MODE:-single}
      - RATE_LIMIT_RPS=${RATE_LIMIT_RPS:-10}
      - ADMIN_TOKEN=${ADMIN_TOKEN}
      - API_JWT_PUBLIC_KEY_PATH=${API_JWT_PUBLIC_KEY_PATH}
      - API_JWT_AUDIENCE=${API_JWT_AUDIENCE}
      # Observability
      - OTEL_EXPORTER_OTLP_ENDPOINT=${OTEL_EXPORTER_OTLP_ENDPOINT}
      - OTEL_SERVICE_NAME=${OTEL_SERVICE_NAME:-liquid-hive-upgrade}
      # Provider keys (no secrets in repo; .env for local only)
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - DEEPSEEK_R1_API_KEY=${DEEPSEEK_R1_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - QWEN_API_KEY=${QWEN_API_KEY}
    # For local CPU-only runs, omit the GPU vLLM service by not enabling the 'gpu' profile.
    # The app will use VLLM_ENDPOINT from config/secrets; default is http://vllm:8000 if present.
    depends_on:
      - prometheus
      - redis
      - neo4j
      - qdrant
    networks: [fusionnet]
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -fsS http://localhost:8000/api/healthz || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/alerts.yml:/etc/prometheus/alerts.yml
    ports:
      - "9090:9090"
    networks: [fusionnet]

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_SMTP_ENABLED=true
      - GF_SMTP_HOST=${GRAFANA_SMTP_HOST}
      - GF_SMTP_USER=${GRAFANA_SMTP_USER}
      - GF_SMTP_PASSWORD=${GRAFANA_SMTP_PASSWORD}
      - GF_SMTP_FROM_ADDRESS=${GRAFANA_SMTP_FROM}
      - GRAFANA_SLACK_CRITICAL_WEBHOOK=${GRAFANA_SLACK_CRITICAL_WEBHOOK}
      - GRAFANA_SLACK_CRITICAL_CHANNEL=${GRAFANA_SLACK_CRITICAL_CHANNEL}
      - GRAFANA_SLACK_WARNING_WEBHOOK=${GRAFANA_SLACK_WARNING_WEBHOOK}
      - GRAFANA_SLACK_WARNING_CHANNEL=${GRAFANA_SLACK_WARNING_CHANNEL}
      - GRAFANA_WEBHOOK_URL=${GRAFANA_WEBHOOK_URL}
      - GRAFANA_PAGER_WEBHOOK=${GRAFANA_PAGER_WEBHOOK}
      - GRAFANA_ALERT_EMAILS=${GRAFANA_ALERT_EMAILS}
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-https://hooks.slack.com/services/your/webhook/url}
    volumes:
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      # - ./grafana/provisioning/alerting:/etc/grafana/provisioning/alerting
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus
    networks: [fusionnet]

  # Redis serves as the message bus for Capsule‑Brain and caching layer.  A simple
  # in‑memory instance suffices for local development.
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks: [fusionnet]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Graph database for the knowledge graph.  Neo4j is used by default; the
  # NEO4J_AUTH environment variable should be updated for production.
  neo4j:
    image: neo4j:5.15
    environment:
      - NEO4J_AUTH=${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-change_this_password}
    ports:
      - "7687:7687"
    networks: [fusionnet]
    healthcheck:
      test: ["CMD", "bash", "-lc", "cypher-shell -u ${NEO4J_USER:-neo4j} -p ${NEO4J_PASSWORD:-change_this_password} 'RETURN 1' || exit 1"]
      interval: 20s
      timeout: 5s
      retries: 10

  # vLLM text model server.  This exposes an OpenAI‑compatible API used by
  # the agent roles and judge.  In production this should run on a GPU host.
  vllm:
    image: vllm/vllm-openai:latest
    profiles:
      - gpu
    environment:
      - MODEL_NAME=llama-2-13b-chat-hf
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - "8001:8000"
    networks: [fusionnet]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -fsS http://localhost:8000/health || exit 1"]
      interval: 20s
      timeout: 5s
      retries: 10

  # Qdrant vector database for production-grade RAG capabilities.
  # Replaces FAISS with a scalable, production-ready vector database.
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    networks: [fusionnet]
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -fsS http://localhost:6333/collections || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 10

  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    networks: [fusionnet]
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
    volumes:
      - ./prometheus/alertmanager.yml:/etc/alertmanager/alertmanager.yml

  # RAG watcher daemon.  Monitors the ingest directory and automatically
  # indexes new documents into the vector store.  Uses the same image as
  # the API since the script resides in this repository.
  rag_watcher:
    build: .
    command: ["python", "-m", "rag_watcher_service"]
    environment:
      - INGEST_WATCH_DIR=/app/data/ingest
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_JSON=${LOG_JSON:-1}
    volumes:
      - ./data/ingest:/app/data/ingest
      - ./data/rag_index:/app/rag_index
      - ./data/qdrant_storage:/app/qdrant_storage
      - ./hivemind/rag:/app/hivemind/rag
      - ./capsule_brain:/app/capsule_brain
    depends_on:
      - api
      - qdrant
    networks: [fusionnet]

networks:
  fusionnet:
    driver: bridge
