# ğŸ§  LIQUID-HIVE

[![CI](https://github.com/AetheronResearch/liquid-hive/workflows/CI/badge.svg)](https://github.com/AetheronResearch/liquid-hive/actions)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://python.org)
[![Node](https://img.shields.io/badge/node-18+-green.svg)](https://nodejs.org)
[![Security](https://img.shields.io/badge/security-bandit-yellow.svg)](https://github.com/PyCQA/bandit)

> **Production-Ready AI Cognitive System** - A unified multi-agent reasoning platform with advanced memory, retrieval, and self-improvement capabilities.

## ğŸš€ Quick Start

**One-command deployment:**

```bash
# Development setup
git clone https://github.com/AetheronResearch/liquid-hive.git
cd liquid-hive
make dev-setup

# Production deployment
docker-compose up --build -d
```

**API Usage:**

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"query": "What is the capital of France?"}'
```

## ğŸ—ï¸ Architecture

Liquid-Hive is a production-grade cognitive system built on a microservices architecture:

### **Core Components**

- ğŸ§  **unified_runtime/** â€“ FastAPI server with dynamic strategy selection
- ğŸ’¾ **capsule_brain/** â€“ Long-term memory and knowledge graph
- ğŸ¤– **hivemind/** â€“ Multi-agent reasoning core with specialized roles
- ğŸ“Š **Observability** â€“ Prometheus metrics + Grafana dashboards
- ğŸŒ **Frontend** â€“ React/TypeScript interface with real-time chat

### **Infrastructure Services**

| Service | Purpose | Port |
|---------|---------|------|
| FastAPI Backend | Core API | 8000 |
| React Frontend | Web Interface | 3000 |
| Redis | Message Bus | 6379 |
| Neo4j | Knowledge Graph | 7474 |
| Qdrant | Vector Database | 6333 |
| Prometheus | Metrics | 9090 |
| Grafana | Dashboards | 3030 |

## ğŸ“¦ Installation

### **Prerequisites**

- Python 3.10+
- Node.js 18+
- Docker & Docker Compose
- 8GB+ RAM (for AI models)

### **Development Setup**

```bash
# Clone and install
git clone https://github.com/AetheronResearch/liquid-hive.git
cd liquid-hive

# Backend setup
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# Frontend setup
cd frontend
yarn install --frozen-lockfile
yarn build

# Start services
docker-compose up --build
```

### **Production Docker**

```bash
# Build production image
docker build -t liquid-hive:latest .

# Deploy with compose
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ”§ Development

### **Makefile Commands**

```bash
# Development
make dev-setup      # Full development environment setup
make install        # Install all dependencies
make test           # Run all tests (Python + Node.js)
make lint           # Run all linters
make format         # Auto-format all code

# Quality & Security
make security-scan  # Run security analysis (bandit)
make type-check     # Run type checking (mypy)
make clean          # Clean build artifacts
make docs           # Build documentation

# Docker
make docker-build   # Build production Docker image
make docker-run     # Run in Docker
make docker-clean   # Clean Docker resources
```

### **Project Structure**

```
liquid-hive/
â”œâ”€â”€ ğŸš€ CI/CD & Config
â”‚   â”œâ”€â”€ .github/workflows/     # GitHub Actions (CI/CD)
â”‚   â”œâ”€â”€ .gitignore            # Git ignore rules
â”‚   â”œâ”€â”€ Makefile              # Development commands
â”‚   â”œâ”€â”€ docker-compose.yml    # Development services
â”‚   â””â”€â”€ Dockerfile            # Production container
â”‚
â”œâ”€â”€ ğŸ§  Core System
â”‚   â”œâ”€â”€ src/                  # Python source code
â”‚   â”‚   â”œâ”€â”€ unified_runtime/  # FastAPI server
â”‚   â”‚   â”œâ”€â”€ capsule_brain/    # Memory & knowledge graph
â”‚   â”‚   â”œâ”€â”€ hivemind/         # Multi-agent reasoning
â”‚   â”‚   â”œâ”€â”€ oracle/           # Quality assurance
â”‚   â”‚   â””â”€â”€ safety/           # Security & validation
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend/             # React TypeScript UI
â”‚   â”‚   â”œâ”€â”€ src/components/   # React components
â”‚   â”‚   â”œâ”€â”€ src/services/     # API clients
â”‚   â”‚   â””â”€â”€ public/           # Static assets
â”‚   â”‚
â”œâ”€â”€ ğŸ—„ï¸ Data & Config
â”‚   â”œâ”€â”€ data/                 # RAG indices & storage
â”‚   â”œâ”€â”€ config/               # Service configurations
â”‚   â”œâ”€â”€ k8s/                  # Kubernetes manifests
â”‚   â””â”€â”€ helm/                 # Helm charts
â”‚
â”œâ”€â”€ ğŸ“Š Observability
â”‚   â”œâ”€â”€ prometheus/           # Metrics collection
â”‚   â”œâ”€â”€ grafana/             # Dashboards
â”‚   â””â”€â”€ docs/                # Documentation
â”‚
â””â”€â”€ ğŸ§ª Testing
    â”œâ”€â”€ tests/               # Python tests
    â””â”€â”€ scripts/             # Utility scripts
```

## ğŸ”— API Reference

### **Chat Endpoint**

```http
POST /api/chat
Content-Type: application/json

{
  "query": "What is quantum computing?",
  "strategy": "comprehensive",  # optional: "fast", "comprehensive", "creative"
  "context": "technical",       # optional context hint
  "max_tokens": 1000           # optional token limit
}
```

**Response:**
```json
{
  "response": "Quantum computing is...",
  "strategy_used": "comprehensive",
  "thinking_process": "...",
  "sources": ["doc1.pdf", "doc2.txt"],
  "confidence": 0.92,
  "processing_time_ms": 1500
}
```

### **Vision Analysis**

```http
POST /api/vision
Content-Type: multipart/form-data

question: "Describe this image"
file: [image.png]
grounding_required: false
```

### **Health Check**

```bash

```bash
curl http://localhost:8000/api/healthz
```

Vision example (multipart):

```bash
curl -X POST "http://localhost:8000/api/vision" \
  -F "question=Describe this image" \
  -F "file=@/path/to/image.png" \
  -F "grounding_required=false"
```

## Training and Selfâ€‘Improvement

Use the scripts in `hivemind/training/` to build datasets from the run logs
stored in the `/data/runs` directory and fineâ€‘tune LoRA adapters. The
dataset builder now employs a _hierarchical Oracle and Arbiter_ pipeline to
refine the system's synthesized answers before they are used for training.
During dataset construction the `Arbiter` consults a primary Oracle
(DeepSeekâ€‘V3) to critique and improve synthesized answers. If the output
fails structural or semantic validation the task is escalated to a
secondary, more powerful Arbiter (GPTâ€‘4o). The resulting
`final_platinum_answer` is used as the target output for SFT/DPO and the
metadata records which model corrected each example are written to
`datasets/training_metadata.jsonl`.

The fineâ€‘tuned adapters can be deployed by updating the `adapter`
path in your configuration. For example, after running the `/train`
endpoint to produce a new adapter the `AdapterDeploymentManager` will
register it as a challenger and route a fraction of requests to it for
A/B testing.

This repository should be treated as a starting point. Additional work is
required to merge the Helm charts, fineâ€‘tune configuration and deploy in
production.

### Controlling the Oracle Pipeline

The Oracle/Arbiter refinement pipeline has been enhanced to use DeepSeek R1 instead of GPT-4o,
providing superior reasoning capabilities at 70% lower cost. The pipeline can be tuned or
disabled entirely through environment variables exposed by `hivemind.config.Settings`.

| Environment Variable        | Default | Description                                                                                                                                                                                                                                                |
| --------------------------- | ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `ENABLE_ORACLE_REFINEMENT`  | `True`  | Master switch for the refinement pipeline. When set to `False` the dataset builder will skip all external API calls and simply use the Judge's synthesized answer. This mode is the fastest and cheapest, suitable for offline or rapid iterations.        |
| `FORCE_DEEPSEEK_R1_ARBITER` | `False` | Forces all refinements to use DeepSeek R1 (reasoning mode) instead of DeepSeek-V3 when `ENABLE_ORACLE_REFINEMENT` is `True`. This provides the highest quality reasoning analysis while maintaining cost efficiency within the unified DeepSeek ecosystem. |

These environment variables can be set in your `.env` file or passed
directly via your orchestration layer (e.g. docker-compose). For example,
to run a fast, lowâ€‘cost training cycle you can disable refinement:

```bash
ENABLE_ORACLE_REFINEMENT=False python -m hivemind.training.dataset_build
```

To force all examples through DeepSeek R1 for enhanced reasoning analysis:

```bash
ENABLE_ORACLE_REFINEMENT=True FORCE_DEEPSEEK_R1_ARBITER=True python -m hivemind.training.dataset_build
```

## Additional Considerations

See docs/ADDITIONAL_CONSIDERATIONS.md for security, observability, migration, performance, testing, and deployment guidance associated with the latest changes.

### Operational Considerations (Summary)

- Security: Input sanitization in /api/chat; keep Approval Queue; use secrets manager (no committed .env).
- Observability: cb\_\* metrics in Grafana; consider SLO alerts for p95 latency, 5xx, token spikes.
- Migration: backend/ removed; unified_runtime is the API entrypoint; foundational_adapter_path centralized.
- Performance/Cost: Economic routing via StrategySelector; cap â€œMasterâ€ usage; gate LoRAX streaming and add rollback.
- Testing: New vision test on ChatPanel; add backend tests for sanitize_input and error handling.

## Final System Analysis & Graduation Report

- Read the comprehensive, honest assessment here: docs/GRADUATION_REPORT.md

## Deployment

For Kubernetes deployment with Helm and GitHub Actions CI/CD, see:

- docs/DEPLOYMENT.md (values, secrets, and workflows)
- .github/workflows (CI build/test/scan; CD for dev/prod)
